{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from collections import Counter, defaultdict\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "from evaluate_by_joining_elements import evaluate_coreference_by_joining_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Did not use initialization regex that was passed: _context_layer._module.weight_ih.*\n",
      "Did not use initialization regex that was passed: _context_layer._module.weight_hh.*\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/coref-spanbert-large-2020.02.27.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading spacy model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/591 [00:00<00:10, 58.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy tokenization of screenplay elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591/591 [00:04<00:00, 121.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding global gold mention positions\n",
      "\t1008 gold mentions\n",
      "\t988 (98.01587301587301%) gold mentions found after parse\n",
      "\t980 (97.22222222222223%) gold mentions' spacy tokenization span found\n",
      "finding gold clusters\n",
      "23 gold clusters\n",
      "finding sys clusters\n",
      "\tusing 'says' after character names\n",
      "\tallennlp coreference resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 sys clusters\n",
      "\n",
      "\n",
      "MUC  : P = 0.7876 R = 0.6782 F1 = 0.7288\n",
      "B3   : P = 0.5691 R = 0.2532 F1 = 0.3505\n",
      "CEAFe: P = 0.2100 R = 0.3653 F1 = 0.2667\n",
      "CoNLL 2012 score: 0.4487\n"
     ]
    }
   ],
   "source": [
    "basterds_result = evaluate_coreference_by_joining_elements(\"data/annotation/basterds.script_parsed.txt\", \"data/annotation/basterds.coref.mapped.csv\", -1, use_speaker_sep=True, coreference_model=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading spacy model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/649 [00:00<00:05, 122.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy tokenization of screenplay elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 649/649 [00:05<00:00, 123.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding global gold mention positions\n",
      "\t911 gold mentions\n",
      "\t894 (98.13391877058177%) gold mentions found after parse\n",
      "\t887 (97.36553238199781%) gold mentions' spacy tokenization span found\n",
      "finding gold clusters\n",
      "38 gold clusters\n",
      "finding sys clusters\n",
      "\tusing 'says' after character names\n",
      "\tallennlp coreference resolution\n",
      "18 sys clusters\n",
      "\n",
      "\n",
      "MUC  : P = 0.9129 R = 0.8021 F1 = 0.8539\n",
      "B3   : P = 0.8308 R = 0.6253 F1 = 0.7135\n",
      "CEAFe: P = 0.6887 R = 0.3262 F1 = 0.4427\n",
      "CoNLL 2012 score: 0.6701\n"
     ]
    }
   ],
   "source": [
    "bourne_result = evaluate_coreference_by_joining_elements(\"data/annotation/bourne.script_parsed.txt\", \"data/annotation/bourne.coref.mapped.csv\", -1, use_speaker_sep=True, coreference_model=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading spacy model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/525 [00:00<00:07, 70.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy tokenization of screenplay elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [00:04<00:00, 113.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding global gold mention positions\n",
      "\t888 gold mentions\n",
      "\t881 (99.21171171171171%) gold mentions found after parse\n",
      "\t880 (99.09909909909909%) gold mentions' spacy tokenization span found\n",
      "finding gold clusters\n",
      "44 gold clusters\n",
      "finding sys clusters\n",
      "\tusing 'says' after character names\n",
      "\tallennlp coreference resolution\n",
      "26 sys clusters\n",
      "\n",
      "\n",
      "MUC  : P = 0.9143 R = 0.8170 F1 = 0.8629\n",
      "B3   : P = 0.6874 R = 0.6628 F1 = 0.6749\n",
      "CEAFe: P = 0.5728 R = 0.3384 F1 = 0.4255\n",
      "CoNLL 2012 score: 0.6544\n"
     ]
    }
   ],
   "source": [
    "shawshank_result = evaluate_coreference_by_joining_elements(\"data/annotation/shawshank.script_parsed.txt\", \"data/annotation/shawshank.coref.mapped.csv\", -1, use_speaker_sep=True, coreference_model=predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nec_f1_score(gold: set, sys: set):\n",
    "    u, v, w = len(gold.intersection(sys)), len(gold), len(sys)\n",
    "    if v:\n",
    "        return 2 * u / (v + w)\n",
    "    else:\n",
    "        return int(w == 0)\n",
    "\n",
    "def evaluate_coreference_nec(gold_entity_to_mentions, sys_clusters, coref_df, document):\n",
    "    pronouns = \"I, me, my, mine, myself, We, us, our, ours, ourselves, you, your, yours, yourself, yourselves, he, him, his, himself, she, her, hers, herself, it, its, itself, they, them, their, theirs, themself, themselves\".lower().split(\", \")\n",
    "\n",
    "    coref_df.PRONOUN |= coref_df.mention.str.lower().isin(pronouns)\n",
    "    document_pronouns = set(coref_df[coref_df.PRONOUN].mention.str.lower().unique()).union(pronouns)\n",
    "\n",
    "    spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "    spacy_document = spacy_nlp(document)\n",
    "\n",
    "    _gold_entity_to_mentions = defaultdict(set)\n",
    "    gold_entity_to_name_mentions = defaultdict(set)\n",
    "    gold_entity_to_names = defaultdict(set)\n",
    "    gold_entity_to_pronoun_mentions = defaultdict(set)\n",
    "    gold_entity_to_nominal_mentions = defaultdict(set)\n",
    "    sys_pronoun_clusters = []\n",
    "    sys_nominal_clusters = []\n",
    "    sys_name_clusters = []\n",
    "\n",
    "    print(\"finding gold names, pronouns and nominals mentions\")\n",
    "    for entity, df in coref_df.groupby(\"entityLabel\"):\n",
    "        name_mentions = set()\n",
    "        pronoun_mentions = set()\n",
    "        nominal_mentions = set()\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            mention = (row.mention_start, row.mention_end)\n",
    "            if row.PRONOUN:\n",
    "                pronoun_mentions.add(mention)\n",
    "            elif row.NOMINAL:\n",
    "                nominal_mentions.add(mention)\n",
    "            else:\n",
    "                name_mentions.add(mention)\n",
    "            \n",
    "        name_mentions.intersection_update(gold_entity_to_mentions[entity])\n",
    "        pronoun_mentions.intersection_update(gold_entity_to_mentions[entity])\n",
    "        nominal_mentions.intersection_update(gold_entity_to_mentions[entity])\n",
    "\n",
    "        if name_mentions:\n",
    "            gold_entity_to_name_mentions[entity] = name_mentions\n",
    "            gold_entity_to_pronoun_mentions[entity] = pronoun_mentions\n",
    "            gold_entity_to_nominal_mentions[entity] = nominal_mentions\n",
    "            _gold_entity_to_mentions[entity] = name_mentions.union(pronoun_mentions).union(nominal_mentions)\n",
    "\n",
    "    gold_entity_to_mentions = _gold_entity_to_mentions\n",
    "    entities = list(gold_entity_to_mentions.keys())\n",
    "\n",
    "    print(\"finding names of entities\")\n",
    "    for entity in entities:\n",
    "        name_mentions = gold_entity_to_name_mentions[entity]\n",
    "        names = set()\n",
    "\n",
    "        for i, j in name_mentions:\n",
    "            char_begin = spacy_document[i].idx\n",
    "            char_end = spacy_document[j].idx + len(spacy_document[j])\n",
    "            text = document[char_begin: char_end]\n",
    "            text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "            spacy_text = spacy_nlp(text)\n",
    "            head_token = [token for token in spacy_text if token.head == token][0]\n",
    "\n",
    "            for noun_chunk in spacy_text.noun_chunks:\n",
    "                contains_proper_noun = any([token.pos_ == \"PROPN\" for token in noun_chunk])\n",
    "                if contains_proper_noun and not noun_chunk.text.islower() and head_token in noun_chunk:\n",
    "                    names.add(noun_chunk.text.lower())\n",
    "            \n",
    "            names.add(text.lower())\n",
    "        \n",
    "        gold_entity_to_names[entity] = names\n",
    "\n",
    "    print(\"finding sys names, pronouns and nominals mentions\")\n",
    "    for mentions in sys_clusters:\n",
    "        pronoun_mentions = set()\n",
    "        nominal_mentions = set()\n",
    "        name_mentions = set()\n",
    "\n",
    "        for i, j in mentions:\n",
    "            char_begin = spacy_document[i].idx\n",
    "            char_end = spacy_document[j].idx + len(spacy_document[j])\n",
    "            text = document[char_begin: char_end]\n",
    "            text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "            spacy_text = spacy_nlp(text)\n",
    "            head_token = [token for token in spacy_text if token.head == token][0]\n",
    "\n",
    "            if text.lower() in document_pronouns:\n",
    "                pronoun_mentions.add((i, j))\n",
    "            elif head_token.pos_ == \"PROPN\":\n",
    "                name_mentions.add((i, j))\n",
    "            else:\n",
    "                nominal_mentions.add((i, j))\n",
    "\n",
    "        sys_pronoun_clusters.append(pronoun_mentions)\n",
    "        sys_nominal_clusters.append(nominal_mentions)\n",
    "        sys_name_clusters.append(name_mentions)\n",
    "\n",
    "    nec_f1_mat = np.zeros((len(entities), len(sys_clusters)))\n",
    "\n",
    "    print(\"calculating nec f1\")\n",
    "    for i, entity in enumerate(entities):\n",
    "        for j, sys_mentions in enumerate(sys_clusters):\n",
    "            for k, l in sys_mentions:\n",
    "                char_begin = spacy_document[k].idx\n",
    "                char_end = spacy_document[l].idx + len(spacy_document[l])\n",
    "                text = document[char_begin: char_end]\n",
    "                text = re.sub(\"\\s+\", \" \", text).strip().lower()\n",
    "                contains_gold_name = any([re.search(\"(^|\\s)\" + re.escape(name) + \"(\\s|$)\", text) is not None for name in gold_entity_to_names[entity]])\n",
    "\n",
    "                if contains_gold_name:\n",
    "                    nec_f1_mat[i, j] = nec_f1_score(gold_entity_to_mentions[entity], sys_mentions)\n",
    "                    break\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(nec_f1_mat, maximize=True)\n",
    "    nec_f1 = nec_f1_mat[row_ind, col_ind].sum()/len(entities)\n",
    "    n_unmatched = (nec_f1_mat[row_ind, col_ind] == 0).sum()\n",
    "\n",
    "    nec_pronoun_f1 = 0\n",
    "    nec_nominal_f1 = 0\n",
    "    nec_name_f1 = 0\n",
    "\n",
    "    for r, c in zip(row_ind, col_ind):\n",
    "        entity = entities[r]\n",
    "        nec_pronoun_f1 += nec_f1_score(gold_entity_to_pronoun_mentions[entity], sys_pronoun_clusters[c])\n",
    "        nec_nominal_f1 += nec_f1_score(gold_entity_to_nominal_mentions[entity], sys_nominal_clusters[c])\n",
    "        nec_name_f1 += nec_f1_score(gold_entity_to_name_mentions[entity], sys_name_clusters[c])\n",
    "\n",
    "    nec_pronoun_f1 /= len(entities)\n",
    "    nec_nominal_f1 /= len(entities)\n",
    "    nec_name_f1 /= len(entities)\n",
    "\n",
    "    print(f\"NEC F1 = {nec_f1:.4f}, chains missed = {n_unmatched} ({100*n_unmatched/len(entities):.2f}%)\")\n",
    "    print(f\"NEC F1 for pronouns = {nec_pronoun_f1:.4f}, nominals = {nec_nominal_f1:.4f}, names = {nec_name_f1:.4f}\")\n",
    "\n",
    "    nec_result = {\"nec_f1\": nec_f1, \"n_unmatched\": n_unmatched, \"nec_pronoun_f1\": nec_pronoun_f1, \"nec_nominal_f1\": nec_nominal_f1, \"nec_name_f1\": nec_name_f1}\n",
    "    meta_info = {\"gold_entities\": entities, \"gold_ind\": row_ind.tolist(), \"sys_ind\": col_ind.tolist()}\n",
    "    nec_result[\"meta_info\"] = meta_info\n",
    "    return nec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_entity_to_cluster = basterds_result[\"gold_clusters\"]\n",
    "sys_clusters = basterds_result[\"sys_clusters\"]\n",
    "coref_df = basterds_result[\"coref_dataframe\"]\n",
    "document = basterds_result[\"document\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding gold names, pronouns and nominals mentions\n",
      "finding names of entities\n",
      "finding sys names, pronouns and nominals mentions\n",
      "calculating nec f1\n",
      "NEC F1 = 0.4201, chains missed = 6 (30.00%)\n",
      "NEC F1 for pronouns = 0.5357, nominals = 0.3763, names = 0.3513\n"
     ]
    }
   ],
   "source": [
    "basterds_nec_result = evaluate_coreference_nec(basterds_result[\"gold_clusters\"], basterds_result[\"sys_clusters\"], basterds_result[\"coref_dataframe\"], basterds_result[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding gold names, pronouns and nominals mentions\n",
      "finding names of entities\n",
      "finding sys names, pronouns and nominals mentions\n",
      "calculating nec f1\n",
      "NEC F1 = 0.4583, chains missed = 5 (41.67%)\n",
      "NEC F1 for pronouns = 0.3680, nominals = 0.7500, names = 0.4461\n"
     ]
    }
   ],
   "source": [
    "bourne_nec_result = evaluate_coreference_nec(bourne_result[\"gold_clusters\"], bourne_result[\"sys_clusters\"], bourne_result[\"coref_dataframe\"], bourne_result[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding gold names, pronouns and nominals mentions\n",
      "finding names of entities\n",
      "finding sys names, pronouns and nominals mentions\n",
      "calculating nec f1\n",
      "NEC F1 = 0.5103, chains missed = 7 (35.00%)\n",
      "NEC F1 for pronouns = 0.5285, nominals = 0.5160, names = 0.5685\n"
     ]
    }
   ],
   "source": [
    "shawshank_nec_result = evaluate_coreference_nec(shawshank_result[\"gold_clusters\"], shawshank_result[\"sys_clusters\"], shawshank_result[\"coref_dataframe\"], shawshank_result[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
