{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mica_text_coref.coref.seq_coref import data\n",
    "from mica_text_coref.coref.seq_coref import util\n",
    "from mica_text_coref.coref.seq_coref import data_util\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train, dev, and test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train documents = 2802\n",
      "Number of dev documents = 343\n",
      "Number of test documents = 348\n",
      "Total number of documents = 3493 documents\n"
     ]
    }
   ],
   "source": [
    "train_corpus = data_util.load_data(\"/home/sbaruah_usc_edu/mica_text_coref/\\\n",
    "data/conll-2012/gold/train.english.jsonlines\")\n",
    "dev_corpus = data_util.load_data(\"/home/sbaruah_usc_edu/mica_text_coref/\\\n",
    "data/conll-2012/gold/dev.english.jsonlines\")\n",
    "test_corpus = data_util.load_data(\"/home/sbaruah_usc_edu/mica_text_coref/\\\n",
    "data/conll-2012/gold/test.english.jsonlines\")\n",
    "\n",
    "corpus = train_corpus + dev_corpus + test_corpus\n",
    "\n",
    "print(f\"Number of train documents = {len(train_corpus.documents)}\")\n",
    "print(f\"Number of dev documents = {len(dev_corpus.documents)}\")\n",
    "print(f\"Number of test documents = {len(test_corpus.documents)}\")\n",
    "print(f\"Total number of documents = {len(corpus.documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `find_disjoint_list_of_largest_mentions` selects the annotated\n",
    "mentions in descending order of size, skipping annotated mentions if they\n",
    "intersect with the annotated mentions already selected. An annotated mention\n",
    "is a tuple of mention and tag (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_disjoint_list_of_largest_mentions(\n",
    "    annotated_mentions: list[tuple[data.Mention, str]]) -> (\n",
    "    list[tuple[data.Mention, str]]):\n",
    "    if len(annotated_mentions) == 0:\n",
    "        return []\n",
    "    annotated_mentions = sorted(annotated_mentions, \n",
    "    key=lambda annotated_mention: len(annotated_mention[0]), reverse=True)\n",
    "    end = max(annotated_mention[0].end for annotated_mention in\n",
    "    annotated_mentions)\n",
    "    covered = np.full(end + 1, fill_value=False, dtype=bool)\n",
    "    selected_annotated_mentions = []\n",
    "    for annotated_mention in annotated_mentions:\n",
    "        mention = annotated_mention[0]\n",
    "        if all(~covered[mention.begin: mention.end + 1]):\n",
    "            selected_annotated_mentions.append(annotated_mention)\n",
    "            covered[mention.begin: mention.end + 1] = True\n",
    "    return selected_annotated_mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 100 random clusters to data/temp/clusters.txt. We observer that most\n",
    "cluster mentions are NPs or noun phrases. Therefore a good representative\n",
    "mention is a noun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/sbaruah_usc_edu/mica_text_coref/data/temp/clusters.txt\", \"w\") \\\n",
    "    as fw:\n",
    "    for i in range(100):\n",
    "        coreference_document = random.choice(corpus.documents)\n",
    "        if len(coreference_document.clusters) == 0:\n",
    "            continue\n",
    "\n",
    "        cluster = random.choice(coreference_document.clusters)\n",
    "        doc_key = coreference_document.doc_key\n",
    "        words = [word for sentence in coreference_document.sentences\n",
    "        for word in sentence]\n",
    "\n",
    "        mention_texts = [\" \".join(words[mention.begin: mention.end + 1])\n",
    "        for mention in cluster]\n",
    "\n",
    "        constituent_annotated_mentions_list: (\n",
    "        list[list[tuple[data.Mention, str]]]) = []\n",
    "        for mention in cluster:\n",
    "            constituent_annotated_mentions = []\n",
    "            for m, constituent_tag in coreference_document.constituents.items():\n",
    "                if mention.begin <= m.begin <= m.end <= mention.end:\n",
    "                    constituent_annotated_mentions.append((m, constituent_tag))\n",
    "            constituent_annotated_mentions = (\n",
    "            find_disjoint_list_of_largest_mentions(\n",
    "                constituent_annotated_mentions))\n",
    "            constituent_annotated_mentions_list.append(\n",
    "                constituent_annotated_mentions)\n",
    "\n",
    "        ner_annotated_mentions_list: list[list[tuple[data.Mention, str]]] = []\n",
    "        for mention in cluster:\n",
    "            ner_annotated_mentions = []\n",
    "            for m, ner_tag in coreference_document.named_entities.items():\n",
    "                if mention.begin <= m.begin <= m.end <= mention.end:\n",
    "                    ner_annotated_mentions.append((m, ner_tag))\n",
    "            ner_annotated_mentions = find_disjoint_list_of_largest_mentions(\n",
    "            ner_annotated_mentions)\n",
    "            ner_annotated_mentions_list.append(ner_annotated_mentions)\n",
    "\n",
    "        fw.write(f\"doc_key = {doc_key}\\n\")\n",
    "        for (mention_text, constituent_annotated_mentions,\n",
    "        ner_annotated_mentions) in zip(\n",
    "            mention_texts, constituent_annotated_mentions_list,\n",
    "            ner_annotated_mentions_list):\n",
    "            fw.write(f\"\\t{mention_text}\\n\")\n",
    "\n",
    "            if len(constituent_annotated_mentions) > 0:\n",
    "                fw.write(\"\\t\\tconstituents:\\n\")\n",
    "                for mention, constituent_tag in constituent_annotated_mentions:\n",
    "                    text = \" \".join(words[mention.begin: mention.end + 1])\n",
    "                    fw.write(f\"\\t\\t\\t{text} [{constituent_tag}]\\n\")\n",
    "            \n",
    "            if len(ner_annotated_mentions) > 0:\n",
    "                fw.write(\"\\t\\tnamed entities:\\n\")\n",
    "                for mention, ner_tag in ner_annotated_mentions:\n",
    "                    text = \" \".join(words[mention.begin: mention.end + 1])\n",
    "                    fw.write(f\"\\t\\t\\t{text} [{ner_tag}]\\n\")\n",
    "        fw.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the set of constituent tags and named entity tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constituent Tags:\n",
      "{'EMBED', 'PRN', 'SINV', 'TOP', 'NAC', 'UCP', 'VP', 'S', 'ADJP', 'SBAR', 'FRAG', 'SQ', 'SBARQ', 'INTJ', 'NX', 'X', 'PP', 'META', 'NML', 'WHPP', 'RRC', 'NP', 'ADVP', 'QP', 'WHADJP', 'CONJP', 'PRT', 'WHNP', 'LST', 'WHADVP'}\n",
      "\n",
      "NER Tags:\n",
      "{'TIME', 'PERCENT', 'MONEY', 'EVENT', 'GPE', 'PRODUCT', 'ORG', 'LAW', 'QUANTITY', 'FAC', 'ORDINAL', 'NORP', 'LANGUAGE', 'WORK_OF_ART', 'CARDINAL', 'LOC', 'DATE', 'PERSON'}\n"
     ]
    }
   ],
   "source": [
    "constituent_tags = set()\n",
    "ner_tags = set()\n",
    "\n",
    "for doc in corpus.documents:\n",
    "    constituent_tags.update(doc.constituents.values())\n",
    "    ner_tags.update(doc.named_entities.values())\n",
    "\n",
    "print(\"Constituent Tags:\")\n",
    "print(constituent_tags)\n",
    "print()\n",
    "print(\"NER Tags:\")\n",
    "print(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the total number of clusters, total number of clusters that contains\n",
    "some noun phrase, and total number of clusters that contains some noun phrase\n",
    "or named entity. We consider person, location, organization, NORP, and GPE named\n",
    "entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43757 clusters, 43325 noun clusters, 43559 noun/ne clusters\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 0\n",
    "n_noun_clusters = 0\n",
    "n_noun_or_ner_clusters = 0\n",
    "\n",
    "for doc in corpus.documents:\n",
    "    words = [word for sentence in doc.sentences for word in sentence]\n",
    "\n",
    "    for cluster in doc.clusters:\n",
    "        contains_NP_mention = False\n",
    "        contains_NER_mention = False\n",
    "        for mention in cluster:\n",
    "            if mention in doc.constituents and (\n",
    "                doc.constituents[mention] == \"NP\"):\n",
    "                contains_NP_mention = True\n",
    "            if mention in doc.named_entities and (\n",
    "                doc.named_entities[mention] in \n",
    "                [\"PERSON\", \"GPE\", \"LOC\", \"NORP\", \"ORG\"]):\n",
    "                contains_NER_mention = True\n",
    "        n_clusters += 1\n",
    "        if contains_NP_mention:\n",
    "            n_noun_clusters += 1\n",
    "        if contains_NP_mention or contains_NER_mention:\n",
    "            n_noun_or_ner_clusters += 1\n",
    "\n",
    "print(f\"{n_clusters} clusters, {n_noun_clusters} noun clusters, \"\n",
    "      f\"{n_noun_or_ner_clusters} noun/ne clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('coreference')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e9e5767629d26198a734ee01c9558510355f25ffdcffebbd890d86f684e7226"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
