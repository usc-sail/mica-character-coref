{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(os.getenv(\"DATA_DIR\"),\n",
    "                           \"mica_text_coref/movie_coref/results/coreference/cross_val_excerpts_Dec19-21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_pattern = re.compile(r\"Epoch = (\\d+)\\n\"\n",
    "                           r\"dev:: loss=([0-9\\.]+), metric:Word=[0-9\\.]+, Span=([0-9\\.]+), Character=[0-9\\.]+\\n\"\n",
    "                           r\"train:: loss=([0-9\\.]+), metric:Word=[0-9\\.]+, Span=([0-9\\.]+), Character=[0-9\\.]+\")\n",
    "\n",
    "for dir_ in os.listdir(results_dir):\n",
    "    if dir_.startswith(\"Dec\"):\n",
    "        log_file = os.path.join(results_dir, dir_, \"train.log\")\n",
    "        result_file = os.path.join(results_dir, dir_, \"result.yaml\")\n",
    "        if not os.path.exists(result_file):\n",
    "            with open(log_file) as f:\n",
    "                content = f.read()\n",
    "            dev_losses, dev_scores, train_losses, train_scores = [], [], [], []\n",
    "            max_dev_score, max_train_score, best_epoch = -1, -1, None\n",
    "            for match in re.finditer(epoch_pattern, content):\n",
    "                epoch = int(match.group(1))\n",
    "                dev_loss, dev_score = float(match.group(2)), float(match.group(3))\n",
    "                train_loss, train_score = float(match.group(4)), float(match.group(5))\n",
    "                if dev_score > max_dev_score:\n",
    "                    best_epoch = epoch\n",
    "                max_dev_score = max(max_dev_score, dev_score)\n",
    "                max_train_score = max(max_train_score, train_score)\n",
    "                dev_losses.append(dev_loss)\n",
    "                dev_scores.append(dev_score)\n",
    "                train_losses.append(train_loss)\n",
    "                train_scores.append(train_score)\n",
    "            preprocess = re.search(r\"preprocess\\s+= (.+)\", content).group(1)\n",
    "            test_movie = re.search(r\"test_movie\\s+= (.+)\", content).group(1)\n",
    "            model_lr = float(re.search(r\"coref_lr\\s+= (.+)\", content).group(1))\n",
    "            bert_lr = float(re.search(r\"bert_lr\\s+= (.+)\", content).group(1))\n",
    "            warmup_steps = float(re.search(r\"warmup_steps\\s+= (.+)\", content).group(1))\n",
    "            result = dict(character_recognition=dict(tag_embedding_size=16,\n",
    "                                                 gru_nlayers=1,\n",
    "                                                 gru_hidden_size=256, \n",
    "                                                 gru_bidirectional=True),\n",
    "                            preprocess=preprocess,\n",
    "                            test_movie=test_movie,\n",
    "                            train_excerpts=True,\n",
    "                            topk=50,\n",
    "                            dropout=0,\n",
    "                            freeze_bert=False,\n",
    "                            genre=\"wb\",\n",
    "                            bce_weight=0.5,\n",
    "                            bert_lr=bert_lr,\n",
    "                            character_lr=model_lr,\n",
    "                            coref_lr=model_lr,\n",
    "                            warmup_steps=warmup_steps,\n",
    "                            weight_decay=1e-3,\n",
    "                            train_document_len=5120,\n",
    "                            train_overlap_len=0,\n",
    "                            dev_document_len=5120,\n",
    "                            dev_overlap_len=512,\n",
    "                            dev_merge_strategy=\"avg\",\n",
    "                            test_document_lens=[5120],\n",
    "                            test_overlap_lens=[512],\n",
    "                            test_merge_strategies=[\"avg\"],\n",
    "                            subword_batch_size=64,\n",
    "                            cr_seq_len=256,\n",
    "                            cr_batch_size=64,\n",
    "                            fn_batch_size=64,\n",
    "                            sp_batch_size=64,\n",
    "                            add_cr_to_coarse=True,\n",
    "                            filter_mentions_by_cr=False,\n",
    "                            remove_singleton_cr=True,\n",
    "                            best_epoch=best_epoch,\n",
    "                            max_epochs=20,\n",
    "                            n_epochs_no_eval=0,\n",
    "                            dev_losses=dev_losses,\n",
    "                            train_losses=train_losses,\n",
    "                            dev_scores=dev_scores,\n",
    "                            train_scores=train_scores,\n",
    "                            dev_metric=dict(span=dict(lea=dict(f1=max_dev_score))),\n",
    "                            train_metric={5120:{512:{\"avg\":dict(span=dict(lea=dict(f1=max_train_score)))}}},\n",
    "                            test_metric=dict(span=dict(lea=dict(f1=max_dev_score)))\n",
    "                        )\n",
    "            result_file2 = os.path.join(results_dir, dir_, \"result2.yaml\")\n",
    "            with open(result_file2, \"w\") as fw:\n",
    "                yaml.dump(result, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 directories with empty results:\n",
      "[]\n",
      "\n",
      "14 settings not experimented\n",
      "preprocess = nocharacters        , bert_lr = 5e-05, model_lr = 1e-04, warmup_steps =    0, test_movie = zootopia\n",
      "preprocess = addsays             , bert_lr = 2e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = nocharacters        , bert_lr = 1e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = dead_poets_society\n",
      "preprocess = regular             , bert_lr = 5e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = regular             , bert_lr = 2e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = addsays             , bert_lr = 1e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = dead_poets_society\n",
      "preprocess = regular             , bert_lr = 1e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = dead_poets_society\n",
      "preprocess = nocharacters        , bert_lr = 5e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = addsays             , bert_lr = 5e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = regular             , bert_lr = 2e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = dead_poets_society\n",
      "preprocess = nocharacters        , bert_lr = 2e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = nocharacters        , bert_lr = 1e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "preprocess = nocharacters        , bert_lr = 5e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = dead_poets_society\n",
      "preprocess = addsays             , bert_lr = 1e-05, model_lr = 1e-04, warmup_steps =   -1, test_movie = avengers_endgame\n",
      "\n",
      "bash script arr\n",
      "nocharacters 5e-05 0.0001 0 zootopia\n",
      "addsays 2e-05 0.0001 -1 avengers_endgame\n",
      "nocharacters 1e-05 0.0001 -1 dead_poets_society\n",
      "regular 5e-05 0.0001 -1 avengers_endgame\n",
      "regular 2e-05 0.0001 -1 avengers_endgame\n",
      "addsays 1e-05 0.0001 -1 dead_poets_society\n",
      "regular 1e-05 0.0001 -1 dead_poets_society\n",
      "nocharacters 5e-05 0.0001 -1 avengers_endgame\n",
      "addsays 5e-05 0.0001 -1 avengers_endgame\n",
      "regular 2e-05 0.0001 -1 dead_poets_society\n",
      "nocharacters 2e-05 0.0001 -1 avengers_endgame\n",
      "nocharacters 1e-05 0.0001 -1 avengers_endgame\n",
      "nocharacters 5e-05 0.0001 -1 dead_poets_society\n",
      "addsays 1e-05 0.0001 -1 avengers_endgame\n"
     ]
    }
   ],
   "source": [
    "settings = set(tuple(x) for x in itertools.product(\n",
    "                    [\"nocharacters\", \"addsays\", \"regular\"], [1e-5, 2e-5, 5e-5], [1e-4, 2e-4, 5e-4], [-1, 0, 50, 100],\n",
    "                    [\"avengers_endgame\", \"dead_poets_society\", \"john_wick\", \"prestige\", \"quiet_place\", \"zootopia\"]))\n",
    "dirs_with_no_results = []\n",
    "\n",
    "for dir_ in os.listdir(results_dir):\n",
    "    if dir_.startswith(\"Dec\"):\n",
    "        result_file1 = os.path.join(results_dir, dir_, \"result.yaml\")\n",
    "        result_file2 = os.path.join(results_dir, dir_, \"result2.yaml\")\n",
    "        result_file = result_file1 if os.path.exists(result_file1) else result_file2\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file, \"r\") as f:\n",
    "                result = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            setting = (result[\"preprocess\"], result[\"bert_lr\"], result[\"coref_lr\"], result[\"warmup_steps\"],\n",
    "                       result[\"test_movie\"])\n",
    "            settings.discard(setting)\n",
    "        else:\n",
    "            dirs_with_no_results.append(dir_)\n",
    "\n",
    "print(f\"{len(dirs_with_no_results)} directories with empty results:\")\n",
    "print(dirs_with_no_results)\n",
    "print()\n",
    "\n",
    "print(f\"{len(settings)} settings not experimented\")\n",
    "for preprocess, bert_lr, model_lr, warmup, movie in settings:\n",
    "    print(f\"preprocess = {preprocess:20s}, bert_lr = {bert_lr:.0e}, model_lr = {model_lr:.0e}, \"\n",
    "          f\"warmup_steps = {warmup:4d}, test_movie = {movie}\")\n",
    "\n",
    "print()\n",
    "print(\"bash script arr\")\n",
    "for preprocess, bert_lr, model_lr, warmup, movie in settings:\n",
    "    print(f\"{preprocess} {bert_lr} {model_lr} {warmup} {movie}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"preprocess\", \"bert_lr\", \"model_lr\", \"warmup\", \"movie\", \"lea\"]\n",
    "rows = []\n",
    "\n",
    "for dir_ in os.listdir(results_dir):\n",
    "    result_file1 = os.path.join(results_dir, dir_, \"result.yaml\")\n",
    "    result_file2 = os.path.join(results_dir, dir_, \"result2.yaml\")\n",
    "    if os.path.exists(result_file1):\n",
    "        with open(result_file1) as f:\n",
    "            result = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    elif os.path.exists(result_file2):\n",
    "        with open(result_file2) as f:\n",
    "            result = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    else:\n",
    "        continue\n",
    "    rows.append([result[\"preprocess\"], result[\"bert_lr\"], result[\"coref_lr\"], result[\"warmup_steps\"],\n",
    "                 result[\"test_movie\"], result[\"dev_metric\"][\"span\"][\"lea\"][\"f1\"]])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(634, 6)\n",
      "preprocess     object\n",
      "bert_lr       float64\n",
      "model_lr      float64\n",
      "warmup        float64\n",
      "movie          object\n",
      "lea           float64\n",
      "dtype: object\n",
      "addsays 1e-05 0.0001 -1.0\n",
      "addsays 2e-05 0.0001 -1.0\n",
      "addsays 5e-05 0.0001 -1.0\n",
      "nocharacters 1e-05 0.0001 -1.0\n",
      "nocharacters 2e-05 0.0001 -1.0\n",
      "nocharacters 5e-05 0.0001 -1.0\n",
      "nocharacters 5e-05 0.0001 0.0\n",
      "regular 1e-05 0.0001 -1.0\n",
      "regular 2e-05 0.0001 -1.0\n",
      "regular 5e-05 0.0001 -1.0\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "\n",
    "for (preprocess, bert_lr, model_lr, warmup), _df in df.groupby([\"preprocess\", \"bert_lr\", \"model_lr\", \"warmup\"]):\n",
    "    if _df.shape[0] != 6:\n",
    "        print(preprocess, bert_lr, model_lr, warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>model_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>64.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">addsays</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>63.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>62.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>62.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.0002</th>\n",
       "      <th>50.0</th>\n",
       "      <td>61.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">nocharacters</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.00001</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.0001</th>\n",
       "      <th>100.0</th>\n",
       "      <td>50.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>50.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.00005</th>\n",
       "      <th>0.0005</th>\n",
       "      <th>0.0</th>\n",
       "      <td>50.126167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0002</th>\n",
       "      <th>-1.0</th>\n",
       "      <td>49.846167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>48.409800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lea\n",
       "preprocess   bert_lr model_lr warmup           \n",
       "regular      0.00002 0.0001   -1.0    64.747500\n",
       "addsays      0.00002 0.0001   -1.0    63.957000\n",
       "             0.00005 0.0001   -1.0    62.494400\n",
       "             0.00001 0.0001   -1.0    62.179000\n",
       "regular      0.00002 0.0002    50.0   61.600000\n",
       "...                                         ...\n",
       "nocharacters 0.00001 0.0001    100.0  50.719000\n",
       "                               0.0    50.707000\n",
       "             0.00005 0.0005    0.0    50.126167\n",
       "                     0.0002   -1.0    49.846167\n",
       "                     0.0001    0.0    48.409800\n",
       "\n",
       "[108 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"preprocess\", \"bert_lr\", \"model_lr\", \"warmup\"]).agg({\"lea\": \"mean\"}).sort_values(by=\"lea\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6d6049dce941f60bb2eec2e35eb23f5ec878ebd724b7ecb8ba7d6ee7900594f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
