{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file: str) -> list[dict[str, any]]:\n",
    "    data = []\n",
    "    for record in jsonlines.open(file):\n",
    "        data.append(record)\n",
    "    return data\n",
    "\n",
    "test_data = read_data(os.path.join(os.getenv(\"DATA_DIR\"), \"mica_text_coref/word_level_coref/data/english_test.jsonlines\"))\n",
    "test_head_data = read_data(os.path.join(os.getenv(\"DATA_DIR\"), \"mica_text_coref/word_level_coref/data/english_test_head.jsonlines\"))\n",
    "wl_data = read_data(os.path.join(os.getenv(\"DATA_DIR\"), \"mica_text_coref/movie_coref/results/nocharacters/dev_wl.jsonlines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data keys:\n",
      "['cased_words', 'clusters', 'deprel', 'document_id', 'head', 'part_id', 'pos', 'sent_id', 'speaker']\n",
      "\n",
      "Test head data keys:\n",
      "['cased_words', 'deprel', 'document_id', 'head', 'head2span', 'part_id', 'pos', 'sent_id', 'span_clusters', 'speaker', 'word_clusters']\n",
      "\n",
      "Movie wl data keys:\n",
      "['cased_words', 'clusters', 'document_id', 'movie', 'ner', 'parse', 'pos', 'rater', 'sent_id', 'sent_offset', 'speaker', 'token']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data keys:\")\n",
    "print(sorted(test_data[0].keys()))\n",
    "print()\n",
    "print(\"Test head data keys:\")\n",
    "print(sorted(test_head_data[0].keys()))\n",
    "print()\n",
    "print(\"Movie wl data keys:\")\n",
    "print(sorted(wl_data[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0053, -1.1427],\n",
      "         [ 1.1517, -0.5650],\n",
      "         [-0.2592,  0.0463],\n",
      "         [-0.7502, -0.3397],\n",
      "         [ 1.3639, -0.6883],\n",
      "         [ 0.5855, -1.4111],\n",
      "         [-0.1561, -0.0643],\n",
      "         [-0.3551, -0.0843],\n",
      "         [ 0.3785, -0.0939],\n",
      "         [ 1.4607,  0.0503]],\n",
      "\n",
      "        [[-1.0029,  0.6369],\n",
      "         [-0.7867,  1.9302],\n",
      "         [-0.7180,  0.9436],\n",
      "         [ 1.0888,  0.7847],\n",
      "         [-0.1953, -1.1461],\n",
      "         [ 2.3971,  1.5287],\n",
      "         [ 0.8477, -1.3446],\n",
      "         [ 0.8969, -0.2355],\n",
      "         [ 1.4858, -2.1018],\n",
      "         [ 0.5305,  0.7799]],\n",
      "\n",
      "        [[-0.4550, -1.1771],\n",
      "         [-0.4935,  0.6656],\n",
      "         [-1.0973, -0.1597],\n",
      "         [-0.3182,  0.0915],\n",
      "         [-1.2603,  0.5439],\n",
      "         [-0.2815, -0.6508],\n",
      "         [ 1.0573, -0.1857],\n",
      "         [ 0.5304,  0.3747],\n",
      "         [ 0.9656, -0.9544],\n",
      "         [-0.4946,  0.6317]],\n",
      "\n",
      "        [[ 1.1656, -0.8925],\n",
      "         [ 1.2404,  0.5655],\n",
      "         [-0.3637, -1.0791],\n",
      "         [-0.0625, -0.6238],\n",
      "         [-0.0642,  0.2093],\n",
      "         [-1.0152, -0.9120],\n",
      "         [-1.7107, -2.1406],\n",
      "         [-1.4862, -0.1132],\n",
      "         [-0.2782,  0.3993],\n",
      "         [-0.1275, -1.5727]],\n",
      "\n",
      "        [[ 3.0125, -0.8138],\n",
      "         [ 0.3376, -0.5527],\n",
      "         [-0.4518, -0.7942],\n",
      "         [-1.0849,  0.7477],\n",
      "         [-1.3466, -0.2871],\n",
      "         [ 1.8179,  0.3310],\n",
      "         [ 0.9555,  0.7195],\n",
      "         [ 1.3161, -0.8686],\n",
      "         [-0.1097,  1.0350],\n",
      "         [ 0.2546, -1.2728]]])\n",
      "tensor([4, 9, 4, 4, 7])\n",
      "tensor([9, 5, 0, 8, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((5, 10, 2))\n",
    "begin = torch.randint(0, 10, (5,))\n",
    "end = torch.randint(0, 10, (5,))\n",
    "print(x)\n",
    "print(begin)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True, False, False,  True])\n",
      "tensor([ True,  True, False,  True,  True])\n",
      "tensor([ True,  True, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "begin_mask = x[torch.arange(5), begin, 0] > 0\n",
    "end_mask = x[torch.arange(5), end, 1] > 0\n",
    "mask = begin_mask & end_mask\n",
    "print(begin_mask)\n",
    "print(end_mask)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0053, -1.1427],\n",
       "         [ 1.1517, -0.5650],\n",
       "         [-0.2592,  0.0463],\n",
       "         [-0.7502, -0.3397],\n",
       "         [ 1.3639, -0.6883],\n",
       "         [ 0.5855, -1.4111],\n",
       "         [-0.1561, -0.0643],\n",
       "         [-0.3551, -0.0843],\n",
       "         [ 0.3785, -0.0939],\n",
       "         [ 1.4607,  0.0503]],\n",
       "\n",
       "        [[-1.0029,  0.6369],\n",
       "         [-0.7867,  1.9302],\n",
       "         [-0.7180,  0.9436],\n",
       "         [ 1.0888,  0.7847],\n",
       "         [-0.1953, -1.1461],\n",
       "         [ 2.3971,  1.5287],\n",
       "         [ 0.8477, -1.3446],\n",
       "         [ 0.8969, -0.2355],\n",
       "         [ 1.4858, -2.1018],\n",
       "         [ 0.5305,  0.7799]],\n",
       "\n",
       "        [[ 3.0125, -0.8138],\n",
       "         [ 0.3376, -0.5527],\n",
       "         [-0.4518, -0.7942],\n",
       "         [-1.0849,  0.7477],\n",
       "         [-1.3466, -0.2871],\n",
       "         [ 1.8179,  0.3310],\n",
       "         [ 0.9555,  0.7195],\n",
       "         [ 1.3161, -0.8686],\n",
       "         [-0.1097,  1.0350],\n",
       "         [ 0.2546, -1.2728]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.load(os.path.join(os.getenv(\"DATA_DIR\"), \"mica_text_coref/word_level_coref/roberta_(e20_2021.05.02_01.16)_release.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bert', 'we', 'rough_scorer', 'pw', 'a_scorer', 'sp', 'epochs_trained'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[\"epochs_trained\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6d6049dce941f60bb2eec2e35eb23f5ec878ebd724b7ecb8ba7d6ee7900594f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
