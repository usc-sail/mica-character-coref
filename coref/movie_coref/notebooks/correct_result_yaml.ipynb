{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mica_text_coref.coref.movie_coref import rules\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "from scorch import scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getenv(\"DATA_DIR\"), \"mica_text_coref/movie_coref/results/coreference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct result files with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories = 220\n",
      "Number of result files = 218\n",
      "Directories with no result file = ['Nov25_05:11:22AM', 'Nov25_05:41:58AM']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_dirs = 0\n",
    "n_result_files = 0\n",
    "dir_with_no_result_files = []\n",
    "keys = []\n",
    "\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir != \"baselines\" and dir != \"logs\" and not dir.startswith(\".\"):\n",
    "        n_dirs += 1\n",
    "        result_file = os.path.join(data_dir, dir, \"result.yaml\")\n",
    "        if os.path.exists(result_file):\n",
    "            n_result_files += 1\n",
    "            with open(result_file) as fr:\n",
    "                result = yaml.load(fr, Loader=yaml.FullLoader)\n",
    "                keys.extend(list(result.keys()))\n",
    "        else:\n",
    "            dir_with_no_result_files.append(dir)\n",
    "\n",
    "print(f\"Number of directories = {n_dirs}\")\n",
    "print(f\"Number of result files = {n_result_files}\")\n",
    "print(f\"Directories with no result file = {dir_with_no_result_files}\\n\")\n",
    "\n",
    "key_distribution = collections.Counter(keys)\n",
    "max_count = max(key_distribution.values())\n",
    "missing_keys = []\n",
    "for key, count in key_distribution.items():\n",
    "    if count < max_count:\n",
    "        print(f\"key={key}, occurs in {count}/{max_count} files\")\n",
    "        missing_keys.append(key)\n",
    "\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir != \"baselines\" and dir != \"logs\" and not dir.startswith(\".\"):\n",
    "        result_file = os.path.join(data_dir, dir, \"result.yaml\")\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file) as fr:\n",
    "                result = yaml.load(fr, Loader=yaml.FullLoader)\n",
    "                if any(key not in result.keys() for key in missing_keys):\n",
    "                    log_file = os.path.join(data_dir, dir, \"train.log\")\n",
    "                    assert os.path.exists(log_file), dir\n",
    "                    with open(log_file, \"r\") as fr:\n",
    "                        content = fr.read()\n",
    "                        if \"preprocess\" not in result.keys():\n",
    "                            match = re.search(r\"train_file\\s+=\\s[\\w/]+/movie_coref/results/([a-z]+)/train\\.jsonlines\", content)\n",
    "                            if match:\n",
    "                                result[\"preprocess\"] = match.group(1)\n",
    "                        if \"warmup\" not in result.keys():\n",
    "                            match = re.search(r\"warmup_epochs\\s+=\\s(.+)\", content)\n",
    "                            if match:\n",
    "                                result[\"warmup\"] = float(match.group(1))\n",
    "                            else:\n",
    "                                result[\"warmup\"] = -1\n",
    "                    with open(result_file, \"w\") as fw:\n",
    "                        yaml.dump(result, fw)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe from result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir != \"baselines\" and dir != \"logs\" and not dir.startswith(\".\"):\n",
    "        result_file = os.path.join(data_dir, dir, \"result.yaml\")\n",
    "        if os.path.exists(result_file):\n",
    "            with open(result_file) as fr:\n",
    "                result = yaml.load(fr, Loader=yaml.FullLoader)\n",
    "                rows.append([dir, result[\"preprocess\"], result[\"bert_lr\"], result[\"coref_lr\"], result[\"character_lr\"], result[\"warmup\"], result[\"weight_decay\"], result[\"dropout\"], \n",
    "                             result[\"epoch\"], result[\"dev_score\"], result[\"train_score\"]])\n",
    "df = pd.DataFrame(rows, columns=[\"dir\", \"preprocess\", \"bert_lr\", \"coref_lr\", \"character_lr\", \"warmup\", \"weight_decay\", \"dropout\", \"epoch\", \"dev_score\", \"train_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best dev performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>coref_lr</th>\n",
       "      <th>character_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dev_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Nov24_11:50:00AM</td>\n",
       "      <td>regular</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>74.057</td>\n",
       "      <td>84.647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dir preprocess  bert_lr  coref_lr  character_lr  warmup  \\\n",
       "53  Nov24_11:50:00AM    regular  0.00002    0.0002        0.0002    -1.0   \n",
       "\n",
       "    weight_decay  dropout  epoch  dev_score  train_score  \n",
       "53         0.001      0.0     11     74.057       84.647  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"dev_score\"] == df[\"dev_score\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best train performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>coref_lr</th>\n",
       "      <th>character_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dev_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Nov24_01:52:20PM</td>\n",
       "      <td>addsays</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>71.877</td>\n",
       "      <td>92.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dir preprocess  bert_lr  coref_lr  character_lr  warmup  \\\n",
       "160  Nov24_01:52:20PM    addsays  0.00002    0.0002        0.0002     1.0   \n",
       "\n",
       "     weight_decay  dropout  epoch  dev_score  train_score  \n",
       "160           0.0      0.0     13     71.877        92.83  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"train_score\"] == df[\"train_score\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation around best dev performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>coref_lr</th>\n",
       "      <th>character_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dev_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Nov24_11:50:00AM</td>\n",
       "      <td>regular</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>74.057</td>\n",
       "      <td>84.647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dir preprocess  bert_lr  coref_lr  character_lr  warmup  \\\n",
       "53  Nov24_11:50:00AM    regular  0.00002    0.0002        0.0002    -1.0   \n",
       "\n",
       "    weight_decay  dropout  epoch  dev_score  train_score  \n",
       "53         0.001      0.0     11     74.057       84.647  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dev_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>coref_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>addsays</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.0002</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>71.737</td>\n",
       "      <td>90.157</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nocharacters</th>\n",
       "      <th>0.00002</th>\n",
       "      <th>0.0002</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>66.653</td>\n",
       "      <td>75.693</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">regular</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.0002</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>70.287</td>\n",
       "      <td>72.453</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.00002</th>\n",
       "      <th>0.0001</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>69.567</td>\n",
       "      <td>75.157</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.0002</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">-1.0</th>\n",
       "      <th>0.000</th>\n",
       "      <th>0.0</th>\n",
       "      <td>70.353</td>\n",
       "      <td>71.340</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>74.057</td>\n",
       "      <td>84.647</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>64.877</td>\n",
       "      <td>64.463</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>72.250</td>\n",
       "      <td>82.840</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>71.853</td>\n",
       "      <td>84.863</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00005</th>\n",
       "      <th>0.0002</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>69.720</td>\n",
       "      <td>79.233</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           dev_score  \\\n",
       "preprocess   bert_lr coref_lr warmup weight_decay dropout              \n",
       "addsays      0.00002 0.0002   -1.0   0.001        0.0         71.737   \n",
       "nocharacters 0.00002 0.0002   -1.0   0.001        0.0         66.653   \n",
       "regular      0.00001 0.0002   -1.0   0.001        0.0         70.287   \n",
       "             0.00002 0.0001   -1.0   0.001        0.0         69.567   \n",
       "                     0.0002   -1.0   0.000        0.0         70.353   \n",
       "                                     0.001        0.0         74.057   \n",
       "                                                  0.3         64.877   \n",
       "                               0.0   0.001        0.0         72.250   \n",
       "                               1.0   0.001        0.0         71.853   \n",
       "             0.00005 0.0002   -1.0   0.001        0.0         69.720   \n",
       "\n",
       "                                                           train_score  epoch  \n",
       "preprocess   bert_lr coref_lr warmup weight_decay dropout                      \n",
       "addsays      0.00002 0.0002   -1.0   0.001        0.0           90.157    7.0  \n",
       "nocharacters 0.00002 0.0002   -1.0   0.001        0.0           75.693    6.0  \n",
       "regular      0.00001 0.0002   -1.0   0.001        0.0           72.453    4.0  \n",
       "             0.00002 0.0001   -1.0   0.001        0.0           75.157    5.0  \n",
       "                     0.0002   -1.0   0.000        0.0           71.340    3.0  \n",
       "                                     0.001        0.0           84.647   11.0  \n",
       "                                                  0.3           64.463    2.0  \n",
       "                               0.0   0.001        0.0           82.840    7.0  \n",
       "                               1.0   0.001        0.0           84.863   10.0  \n",
       "             0.00005 0.0002   -1.0   0.001        0.0           79.233    5.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = [\"preprocess\", \"bert_lr\", \"coref_lr\", \"warmup\", \"weight_decay\", \"dropout\"]\n",
    "best_dev_vars = df[df[\"dev_score\"] == df[\"dev_score\"].max()].iloc[0].to_dict()\n",
    "index = np.full((len(df),), False, dtype=bool)\n",
    "for i, row in df.iterrows():\n",
    "    n_diff = sum(int(best_dev_vars[var] != row[var]) for var in vars)\n",
    "    index[i] = n_diff == 1 or n_diff == 0\n",
    "display(df[df[\"dev_score\"] == df[\"dev_score\"].max()])\n",
    "df[index].groupby(vars)[[\"dev_score\", \"train_score\", \"epoch\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>coref_lr</th>\n",
       "      <th>character_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dev_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Nov24_07:54:17AM</td>\n",
       "      <td>nocharacters</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>66.653</td>\n",
       "      <td>75.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Nov24_11:50:00AM</td>\n",
       "      <td>regular</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>74.057</td>\n",
       "      <td>84.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Nov24_11:16:00AM</td>\n",
       "      <td>addsays</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>71.737</td>\n",
       "      <td>90.157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dir    preprocess  bert_lr  coref_lr  character_lr  warmup  \\\n",
       "51   Nov24_07:54:17AM  nocharacters  0.00002    0.0002        0.0002    -1.0   \n",
       "53   Nov24_11:50:00AM       regular  0.00002    0.0002        0.0002    -1.0   \n",
       "212  Nov24_11:16:00AM       addsays  0.00002    0.0002        0.0002    -1.0   \n",
       "\n",
       "     weight_decay  dropout  epoch  dev_score  train_score  \n",
       "51          0.001      0.0      6     66.653       75.693  \n",
       "53          0.001      0.0     11     74.057       84.647  \n",
       "212         0.001      0.0      7     71.737       90.157  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"bert_lr\"] == 2e-5) & (df[\"coref_lr\"] == 2e-4) & (df[\"warmup\"] == -1) & (df[\"weight_decay\"] == 1e-3) & (df[\"dropout\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_arr, nocharacters_arr, addsays_arr = [], [], []\n",
    "for (bert_lr, coref_lr, warmup, weight_decay, dropout), _df in df.groupby([\"bert_lr\", \"coref_lr\", \"warmup\", \"weight_decay\", \"dropout\"]):\n",
    "    if _df[\"preprocess\"].unique().size == 3:\n",
    "        regular_arr.append(_df.loc[_df[\"preprocess\"] == \"regular\", \"dev_score\"].mean())\n",
    "        nocharacters_arr.append(_df.loc[_df[\"preprocess\"] == \"nocharacters\", \"dev_score\"].mean())\n",
    "        addsays_arr.append(_df.loc[_df[\"preprocess\"] == \"addsays\", \"dev_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=15.263022247251326, pvalue=8.270439515480995e-24)\n",
      "Ttest_relResult(statistic=-2.1985598411997276, pvalue=0.03126536534398492)\n",
      "Ttest_relResult(statistic=19.461034458275336, pvalue=9.916310764718426e-30)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_rel(regular_arr, nocharacters_arr))\n",
    "print(stats.ttest_rel(regular_arr, addsays_arr))\n",
    "print(stats.ttest_rel(addsays_arr, nocharacters_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nocharacters < regular = addsays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dir</th>\n",
       "      <th>preprocess</th>\n",
       "      <th>bert_lr</th>\n",
       "      <th>coref_lr</th>\n",
       "      <th>character_lr</th>\n",
       "      <th>warmup</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dev_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Nov24_11:50:00AM</td>\n",
       "      <td>regular</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>74.057</td>\n",
       "      <td>84.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Nov24_12:49:03PM</td>\n",
       "      <td>regular</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>64.877</td>\n",
       "      <td>64.463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dir preprocess  bert_lr  coref_lr  character_lr  warmup  \\\n",
       "53   Nov24_11:50:00AM    regular  0.00002    0.0002        0.0002    -1.0   \n",
       "167  Nov24_12:49:03PM    regular  0.00002    0.0002        0.0002    -1.0   \n",
       "\n",
       "     weight_decay  dropout  epoch  dev_score  train_score  \n",
       "53          0.001      0.0     11     74.057       84.647  \n",
       "167         0.001      0.3      2     64.877       64.463  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"preprocess\"] == \"regular\") & (df[\"bert_lr\"] == 2e-5) & (df[\"coref_lr\"] == 2e-4) & (df[\"warmup\"] == -1) & (df[\"weight_decay\"] == 1e-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodropout_arr, dropout_arr = [], []\n",
    "for (preprocess, bert_lr, coref_lr, warmup, weight_decay), _df in df.groupby([\"preprocess\", \"bert_lr\", \"coref_lr\", \"warmup\", \"weight_decay\"]):\n",
    "    if _df[\"dropout\"].unique().size == 2:\n",
    "        nodropout_arr.append(_df.loc[_df[\"dropout\"] == 0, \"dev_score\"].mean())\n",
    "        dropout_arr.append(_df.loc[_df[\"dropout\"] == 0.3, \"dev_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=15.816380621388703, pvalue=1.5136944788478756e-29)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_rel(nodropout_arr, dropout_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3 dropout < zero dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test bert_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all schedules\n",
      "Ttest_relResult(statistic=-7.8190532065541305, pvalue=4.282835688950486e-11)\n",
      "Ttest_relResult(statistic=3.9504100043621757, pvalue=0.00018585459464098706)\n",
      "Ttest_relResult(statistic=1.5372265351848184, pvalue=0.1288111778336569)\n",
      "\n",
      "no schedule\n",
      "Ttest_relResult(statistic=-3.575218660571907, pvalue=0.0016045039622772208)\n",
      "Ttest_relResult(statistic=2.2235320439592994, pvalue=0.03628478137232081)\n",
      "Ttest_relResult(statistic=0.1415415007288095, pvalue=0.8886746438759797)\n",
      "\n",
      "schedule with no warmup\n",
      "Ttest_relResult(statistic=-5.799541919010412, pvalue=6.572239376443888e-06)\n",
      "Ttest_relResult(statistic=2.743894121747891, pvalue=0.011564218008498238)\n",
      "Ttest_relResult(statistic=0.8819148945785081, pvalue=0.38694698847148434)\n",
      "\n",
      "schedule with 1 epoch warmup\n",
      "Ttest_relResult(statistic=-4.304604688611293, pvalue=0.0003136206264990181)\n",
      "Ttest_relResult(statistic=1.815614447345321, pvalue=0.08373685935248419)\n",
      "Ttest_relResult(statistic=1.763896882076014, pvalue=0.09229367535305728)\n"
     ]
    }
   ],
   "source": [
    "bert_1eminus5_arr, bert_2eminus5_arr, bert_5eminus5_arr = [], [], []\n",
    "for _, _df in df.groupby([\"preprocess\", \"coref_lr\", \"warmup\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"bert_lr\"].unique().size == 3:\n",
    "    bert_1eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 1e-5, \"dev_score\"].mean()) \n",
    "    bert_2eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 2e-5, \"dev_score\"].mean()) \n",
    "    bert_5eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 5e-5, \"dev_score\"].mean())\n",
    "print(\"all schedules\")\n",
    "print(stats.ttest_rel(bert_1eminus5_arr, bert_2eminus5_arr))\n",
    "print(stats.ttest_rel(bert_2eminus5_arr, bert_5eminus5_arr))\n",
    "print(stats.ttest_rel(bert_5eminus5_arr, bert_1eminus5_arr))\n",
    "print()\n",
    "\n",
    "bert_1eminus5_arr, bert_2eminus5_arr, bert_5eminus5_arr = [], [], []\n",
    "for _, _df in df[df[\"warmup\"] == -1].groupby([\"preprocess\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"bert_lr\"].unique().size == 3:\n",
    "    bert_1eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 1e-5, \"dev_score\"].mean()) \n",
    "    bert_2eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 2e-5, \"dev_score\"].mean()) \n",
    "    bert_5eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 5e-5, \"dev_score\"].mean())\n",
    "print(\"no schedule\")\n",
    "print(stats.ttest_rel(bert_1eminus5_arr, bert_2eminus5_arr))\n",
    "print(stats.ttest_rel(bert_2eminus5_arr, bert_5eminus5_arr))\n",
    "print(stats.ttest_rel(bert_5eminus5_arr, bert_1eminus5_arr))\n",
    "print()\n",
    "\n",
    "bert_1eminus5_arr, bert_2eminus5_arr, bert_5eminus5_arr = [], [], []\n",
    "for _, _df in df[df[\"warmup\"] == 0].groupby([\"preprocess\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"bert_lr\"].unique().size == 3:\n",
    "    bert_1eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 1e-5, \"dev_score\"].mean()) \n",
    "    bert_2eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 2e-5, \"dev_score\"].mean()) \n",
    "    bert_5eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 5e-5, \"dev_score\"].mean())\n",
    "print(\"schedule with no warmup\")\n",
    "print(stats.ttest_rel(bert_1eminus5_arr, bert_2eminus5_arr))\n",
    "print(stats.ttest_rel(bert_2eminus5_arr, bert_5eminus5_arr))\n",
    "print(stats.ttest_rel(bert_5eminus5_arr, bert_1eminus5_arr))\n",
    "print()\n",
    "\n",
    "bert_1eminus5_arr, bert_2eminus5_arr, bert_5eminus5_arr = [], [], []\n",
    "for _, _df in df[df[\"warmup\"] == 1].groupby([\"preprocess\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"bert_lr\"].unique().size == 3:\n",
    "    bert_1eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 1e-5, \"dev_score\"].mean()) \n",
    "    bert_2eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 2e-5, \"dev_score\"].mean()) \n",
    "    bert_5eminus5_arr.append(_df.loc[_df[\"bert_lr\"] == 5e-5, \"dev_score\"].mean())\n",
    "print(\"schedule with 1 epoch warmup\")\n",
    "print(stats.ttest_rel(bert_1eminus5_arr, bert_2eminus5_arr))\n",
    "print(stats.ttest_rel(bert_2eminus5_arr, bert_5eminus5_arr))\n",
    "print(stats.ttest_rel(bert_5eminus5_arr, bert_1eminus5_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all schedules, bert_lr 2e-5 > 1e-5, 5e-5\n",
    "\n",
    "for no schedule, bert_lr 2e-5 > 1e-5\n",
    "\n",
    "for schedule with 0 warmup, 2e-5 > 1e-5\n",
    "\n",
    "for schedule with 1 epoch warmup, 2e-5 > 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test coref/character_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all schedules Ttest_relResult(statistic=-0.6535535711576492, pvalue=0.5148281437947139)\n",
      "no schedule Ttest_relResult(statistic=0.044817163586460096, pvalue=0.9645077746396036)\n",
      "schedule with no warmup Ttest_relResult(statistic=-0.37071766044614485, pvalue=0.7130821910911166)\n",
      "schedule with 1 epoch warmup Ttest_relResult(statistic=-0.9971205120639133, pvalue=0.3259617579514006)\n"
     ]
    }
   ],
   "source": [
    "coref_1eminus4_arr, coref_2eminus4_arr = [], []\n",
    "for _, _df in df.groupby([\"preprocess\", \"bert_lr\", \"warmup\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"coref_lr\"].unique().size == 2:\n",
    "      coref_1eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 1e-4, \"dev_score\"].mean()) \n",
    "      coref_2eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 2e-4, \"dev_score\"].mean())\n",
    "print(\"all schedules\", stats.ttest_rel(coref_2eminus4_arr, coref_1eminus4_arr))\n",
    "\n",
    "coref_1eminus4_arr, coref_2eminus4_arr = [], []\n",
    "for _, _df in df[df[\"warmup\"] == -1].groupby([\"preprocess\", \"bert_lr\", \"warmup\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"coref_lr\"].unique().size == 2:\n",
    "      coref_1eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 1e-4, \"dev_score\"].mean()) \n",
    "      coref_2eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 2e-4, \"dev_score\"].mean())\n",
    "print(\"no schedule\", stats.ttest_rel(coref_2eminus4_arr, coref_1eminus4_arr))\n",
    "\n",
    "coref_1eminus4_arr, coref_2eminus4_arr = [], []\n",
    "for _, _df in df[df[\"warmup\"] == 0].groupby([\"preprocess\", \"bert_lr\", \"warmup\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"coref_lr\"].unique().size == 2:\n",
    "      coref_1eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 1e-4, \"dev_score\"].mean()) \n",
    "      coref_2eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 2e-4, \"dev_score\"].mean())\n",
    "print(\"schedule with no warmup\", stats.ttest_rel(coref_2eminus4_arr, coref_1eminus4_arr))\n",
    "\n",
    "coref_1eminus4_arr, coref_2eminus4_arr = [], []\n",
    "for _, _df in df[df[\"warmup\"] == 1].groupby([\"preprocess\", \"bert_lr\", \"warmup\", \"weight_decay\", \"dropout\"]):\n",
    "   if _df[\"coref_lr\"].unique().size == 2:\n",
    "      coref_1eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 1e-4, \"dev_score\"].mean()) \n",
    "      coref_2eminus4_arr.append(_df.loc[_df[\"coref_lr\"] == 2e-4, \"dev_score\"].mean())\n",
    "print(\"schedule with 1 epoch warmup\", stats.ttest_rel(coref_2eminus4_arr, coref_1eminus4_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all schedules, coref_lr 1e-4 = 2e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All learning rates\n",
      "Ttest_relResult(statistic=0.24825556530949816, pvalue=0.8046740418482301)\n",
      "Ttest_relResult(statistic=1.3777702391129951, pvalue=0.17272647347293318)\n",
      "Ttest_relResult(statistic=-1.9390689959803296, pvalue=0.05658330061898119)\n",
      "\n",
      "bert_lr = 1e-5\n",
      "Ttest_relResult(statistic=1.5741549216795436, pvalue=0.1291080469314441)\n",
      "Ttest_relResult(statistic=1.2633848340927663, pvalue=0.21910777894732586)\n",
      "Ttest_relResult(statistic=-2.7829520790948465, pvalue=0.010575865179234076)\n",
      "\n",
      "bert_lr = 2e-5\n",
      "Ttest_relResult(statistic=-0.34667574960968883, pvalue=0.7319866516876962)\n",
      "Ttest_relResult(statistic=2.272780511286195, pvalue=0.0326996084395385)\n",
      "Ttest_relResult(statistic=-1.8588312081624148, pvalue=0.07589421506888916)\n",
      "\n",
      "bert_lr = 5e-5\n",
      "Ttest_relResult(statistic=-0.0703899917077399, pvalue=0.9445492794941016)\n",
      "Ttest_relResult(statistic=0.020829289782804426, pvalue=0.9835784781766992)\n",
      "Ttest_relResult(statistic=0.059389741488134896, pvalue=0.9532032285565804)\n"
     ]
    }
   ],
   "source": [
    "noschedule_arr, schedulezerowarmup_arr, scheduleonewarmup_arr = [], [], []\n",
    "for _, _df in df.groupby([\"preprocess\", \"bert_lr\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "    if _df[\"warmup\"].unique().size == 3:\n",
    "        noschedule_arr.append(_df.loc[_df[\"warmup\"] == -1, \"dev_score\"].mean())\n",
    "        schedulezerowarmup_arr.append(_df.loc[_df[\"warmup\"] == 0, \"dev_score\"].mean())\n",
    "        scheduleonewarmup_arr.append(_df.loc[_df[\"warmup\"] == 1, \"dev_score\"].mean())\n",
    "print(\"All learning rates\")\n",
    "print(stats.ttest_rel(noschedule_arr, schedulezerowarmup_arr))\n",
    "print(stats.ttest_rel(schedulezerowarmup_arr, scheduleonewarmup_arr))\n",
    "print(stats.ttest_rel(scheduleonewarmup_arr, noschedule_arr))\n",
    "print()\n",
    "\n",
    "noschedule_arr, schedulezerowarmup_arr, scheduleonewarmup_arr = [], [], []\n",
    "for _, _df in df[df[\"bert_lr\"] == 1e-5].groupby([\"preprocess\", \"bert_lr\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "    if _df[\"warmup\"].unique().size == 3:\n",
    "        noschedule_arr.append(_df.loc[_df[\"warmup\"] == -1, \"dev_score\"].mean())\n",
    "        schedulezerowarmup_arr.append(_df.loc[_df[\"warmup\"] == 0, \"dev_score\"].mean())\n",
    "        scheduleonewarmup_arr.append(_df.loc[_df[\"warmup\"] == 1, \"dev_score\"].mean())\n",
    "print(\"bert_lr = 1e-5\")\n",
    "print(stats.ttest_rel(noschedule_arr, schedulezerowarmup_arr))\n",
    "print(stats.ttest_rel(schedulezerowarmup_arr, scheduleonewarmup_arr))\n",
    "print(stats.ttest_rel(scheduleonewarmup_arr, noschedule_arr))\n",
    "print()\n",
    "\n",
    "noschedule_arr, schedulezerowarmup_arr, scheduleonewarmup_arr = [], [], []\n",
    "for _, _df in df[df[\"bert_lr\"] == 2e-5].groupby([\"preprocess\", \"bert_lr\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "    if _df[\"warmup\"].unique().size == 3:\n",
    "        noschedule_arr.append(_df.loc[_df[\"warmup\"] == -1, \"dev_score\"].mean())\n",
    "        schedulezerowarmup_arr.append(_df.loc[_df[\"warmup\"] == 0, \"dev_score\"].mean())\n",
    "        scheduleonewarmup_arr.append(_df.loc[_df[\"warmup\"] == 1, \"dev_score\"].mean())\n",
    "print(\"bert_lr = 2e-5\")\n",
    "print(stats.ttest_rel(noschedule_arr, schedulezerowarmup_arr))\n",
    "print(stats.ttest_rel(schedulezerowarmup_arr, scheduleonewarmup_arr))\n",
    "print(stats.ttest_rel(scheduleonewarmup_arr, noschedule_arr))\n",
    "print()\n",
    "\n",
    "noschedule_arr, schedulezerowarmup_arr, scheduleonewarmup_arr = [], [], []\n",
    "for _, _df in df[df[\"bert_lr\"] == 5e-5].groupby([\"preprocess\", \"bert_lr\", \"coref_lr\", \"weight_decay\", \"dropout\"]):\n",
    "    if _df[\"warmup\"].unique().size == 3:\n",
    "        noschedule_arr.append(_df.loc[_df[\"warmup\"] == -1, \"dev_score\"].mean())\n",
    "        schedulezerowarmup_arr.append(_df.loc[_df[\"warmup\"] == 0, \"dev_score\"].mean())\n",
    "        scheduleonewarmup_arr.append(_df.loc[_df[\"warmup\"] == 1, \"dev_score\"].mean())\n",
    "print(\"bert_lr = 5e-5\")\n",
    "print(stats.ttest_rel(noschedule_arr, schedulezerowarmup_arr))\n",
    "print(stats.ttest_rel(schedulezerowarmup_arr, scheduleonewarmup_arr))\n",
    "print(stats.ttest_rel(scheduleonewarmup_arr, noschedule_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for all learning rates, no schedule = schedule with 0 warmup = schedule with 1 epoch warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test if removing characters from addsays/nocharacters decrease score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "with jsonlines.open(os.path.join(data_dir, \"Nov24_11:50:00AM\", \"dev.jsonlines\"), \"r\") as reader:\n",
    "    dev_data = [doc for doc in reader]\n",
    "print(len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.02178441484585\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "for doc in dev_data:\n",
    "    gold_clusters = [set((mention[0], mention[1]) for mention in cluster) for cluster in doc[\"gold\"]]\n",
    "    pred_clusters = [set(tuple(span) for span in cluster) for cluster in doc[\"pred_span\"]]\n",
    "    parse = doc[\"parse\"]\n",
    "\n",
    "    # # remove speakers\n",
    "    # for i, clusters in enumerate([gold_clusters, pred_clusters]):\n",
    "    #     _clusters = []\n",
    "    #     for cluster in clusters:\n",
    "    #         _cluster = set()\n",
    "    #         for i, j in cluster:\n",
    "    #             if set(parse[i: j + 1]).pop() != \"C\":\n",
    "    #                 _cluster.add((i, j))\n",
    "    #         if _cluster:\n",
    "    #             _clusters.append(_cluster)\n",
    "    #     if i == 0:\n",
    "    #         gold_clusters = _clusters\n",
    "    #     else:\n",
    "    #         pred_clusters = _clusters\n",
    "    \n",
    "    # Merge speakers\n",
    "    # pred_clusters = rules.merge_speakers(doc[\"token\"], doc[\"parse\"], pred_clusters)\n",
    "\n",
    "    # Keep speakers\n",
    "    # pred_clusters = rules.keep_speakers(doc[\"parse\"], pred_clusters)\n",
    "\n",
    "    f1 = 100*scores.conll2012(gold_clusters, pred_clusters)\n",
    "    f1s.append(f1)\n",
    "print(np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('coreference')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6d6049dce941f60bb2eec2e35eb23f5ec878ebd724b7ecb8ba7d6ee7900594f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
